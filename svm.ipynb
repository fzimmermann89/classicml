{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Support Vector Machines\n",
    "\n",
    "We will implement a kernel SVM. Our implementation will be based on a generic quadratic programming optimizer provided in CVXOPT. The SVM will then be tested on the UCI breast cancer dataset, a simple binary classification dataset accessible via the `scikit-learn` library.\n",
    "\n",
    "## Defining the Gaussian Kernel\n",
    "\n",
    "As a starting point, we would like to implement the Gaussian kernel, which we will make use of in our kernel SVM implementation. It is defined as:\n",
    "$$\n",
    "k(x,x') = \\exp \\Big( -\\frac{\\|x-x'\\|^2}{2 \\sigma^2} \\Big)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#some imports\n",
    "import numpy, scipy, scipy.spatial\n",
    "import sklearn,sklearn.datasets\n",
    "import cvxopt, cvxopt.solvers\n",
    "cvxopt.solvers.options[\"show_progress\"] = False\n",
    "\n",
    "def GaussianKernel(X1, X2, s):\n",
    "    return numpy.exp(\n",
    "        -scipy.spatial.distance.cdist(X1, X2, \"sqeuclidean\") / (2 * (s ** 2))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating the problem compatible to CVXOPT Quadratic Solver\n",
    "\n",
    "We would like to learn a nonlinear SVM by optimizing its dual. An advantage of the dual SVM compared to the primal SVM is that it allows to use nonlinear kernels such as the Gaussian kernel. The dual SVM consists of solving the following quadratic program:\n",
    "\n",
    "$$\n",
    "\\max_\\alpha \\sum_{i=1}^N \\alpha_i - \\frac12 \\sum_{ij} \\alpha_i \\alpha_j y_i y_j k(x_i,x_j)\n",
    "\\qquad \n",
    "\\text{subject to:}\n",
    "\\qquad 0 \\leq \\alpha_i \\leq C \\qquad \\text{and} \\qquad \\sum_{i=1}^N \\alpha_i y_i = 0.\n",
    "$$\n",
    "\n",
    "We would like to rely on a CVXOPT solver to obtain a solution to our SVM dual. QP solves an optimization problem of the type:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\min_{\\boldsymbol{x}} \\quad &\\frac12 \\boldsymbol{x}^\\top P \\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x}\\\\\n",
    "\\text{subject to} \\quad & G \\boldsymbol{x} \\preceq \\boldsymbol{h}\\\\\n",
    "\\text{and} \\quad & A \\boldsymbol{x} = \\boldsymbol{b}.\n",
    "\\end{align*}\n",
    "$$\n",
    "which is of similar form to our dual SVM (note that $\\boldsymbol{x}$ will correspond to the parameters $(\\alpha_i)_i$ of the SVM). We need to build the data structures (vectors and matrices) that makes solving this quadratic problem equivalent to solving our dual SVM:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P=y^Ty K \\in R^{NxN}\\\\\n",
    "q=-\\boldsymbol{1} \\in R^N\\\\\n",
    "G=\\begin{pmatrix} \n",
    "-\\boldsymbol{I}\\\\ \n",
    "\\boldsymbol{I}\n",
    "\\end{pmatrix} \\in R^{NxN}\\\\\n",
    "h=C*\\begin{pmatrix} \n",
    "\\boldsymbol{0}\\\\ \n",
    "\\boldsymbol{1}\n",
    "\\end{pmatrix} \\in R^{2N}\\\\\n",
    "A=y^T\\\\\n",
    "b=0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "with $\\boldsymbol{1}$ and $\\boldsymbol{0}$ a $R^N$ vector of all ones/zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getQPMatrices(K, T, C):\n",
    "    n_samples = len(K)\n",
    "    P = cvxopt.matrix(numpy.outer(T, T) * K)\n",
    "    q = cvxopt.matrix(numpy.ones(n_samples) * -1)\n",
    "    G = cvxopt.matrix(numpy.vstack((\n",
    "        -numpy.identity(n_samples), \n",
    "        numpy.identity(n_samples))\n",
    "    ))\n",
    "    h = cvxopt.matrix(numpy.hstack((\n",
    "        numpy.zeros(n_samples), \n",
    "        numpy.ones(n_samples))\n",
    "    )) * C\n",
    "    A = cvxopt.matrix(T, (1, n_samples))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "\n",
    "    return P, q, G, h, A, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given the parameters $(\\alpha_i)_i$ the optimization procedure has found, the prediction of the SVM is given by:\n",
    "\n",
    "$$\n",
    "f(x) = \\text{sign}\\Big(\\sum_{i=1}^N \\alpha_i y_i k(x,x_i) + \\theta\\Big)\n",
    "$$\n",
    "\n",
    "With the bias $\\theta$ obtained from any support vector that lies exactly on the margin, or equivalently, whose associated parameter $\\alpha$ is not equal to $0$ or $C$. Calling one such vector \"$x_M$\", the parameter $\\theta$ can be computed as:\n",
    "\n",
    "$$\n",
    "\\theta =  y_M - \\sum_{j=1}^N \\alpha_j y_j k(x_M,x_j) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def Theta(K, T, alpha, C):\n",
    "    # picking the vector\n",
    "    m = numpy.argmax(\n",
    "        numpy.logical_and(\n",
    "            ~numpy.isclose(alpha, 0, atol=1e-5), \n",
    "            ~numpy.isclose(alpha, C, atol=1e-5)\n",
    "        )\n",
    "    )\n",
    "    # too lazy to vectorize, no significant impact on runtime\n",
    "    theta = T[m] - sum((alpha[j] * T[j] * K[m, j] for j in range(len(K))))\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianSVM\n",
    "\n",
    "Putting all together, we can create a GaussianSVM class with a fit and a predict function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianSVM:\n",
    "    def __init__(self, C=1.0, scale=1.0):\n",
    "\n",
    "        self.C, self.scale = C, scale\n",
    "\n",
    "    def fit(self, X, T):\n",
    "        K = GaussianKernel(X, X, self.scale)\n",
    "        P, q, G, h, A, b = getQPMatrices(K, T, self.C)\n",
    "        sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        alpha = numpy.array(sol[\"x\"])\n",
    "        self.theta = Theta(K, T, alpha, self.C)\n",
    "        #alpha!=0 is support vector, test with some margin to account for precision\n",
    "        issupport = alpha[:, 0] > 1e-6 * alpha.mean()\n",
    "        self.alpha = alpha[issupport]\n",
    "        self.X = X[issupport]\n",
    "        self.T = T[issupport]\n",
    "\n",
    "    def predict(self, X):\n",
    "        k = GaussianKernel(X, self.X, self.scale)\n",
    "        f = numpy.sum(self.alpha.T * self.T[None, :] * k, 1) + self.theta\n",
    "        return numpy.sign(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Classifier\n",
    "\n",
    "The following code tests the SVM on some breast cancer binary classification dataset for a range of scale and soft-margin parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=     30.0  C=     10.0  nSV:  188  train: 0.999  test: 0.926\n",
      "scale=     30.0  C=    100.0  nSV:  170  train: 1.000  test: 0.923\n",
      "scale=     30.0  C=   1000.0  nSV:  177  train: 1.000  test: 0.923\n",
      "scale=     30.0  C=  10000.0  nSV:  183  train: 1.000  test: 0.923\n",
      "\n",
      "scale=    100.0  C=     10.0  nSV:  109  train: 0.961  test: 0.943\n",
      "scale=    100.0  C=    100.0  nSV:   92  train: 0.986  test: 0.944\n",
      "scale=    100.0  C=   1000.0  nSV:   77  train: 0.998  test: 0.927\n",
      "scale=    100.0  C=  10000.0  nSV:   62  train: 1.000  test: 0.925\n",
      "\n",
      "scale=    300.0  C=     10.0  nSV:  105  train: 0.937  test: 0.931\n",
      "scale=    300.0  C=    100.0  nSV:   58  train: 0.961  test: 0.945\n",
      "scale=    300.0  C=   1000.0  nSV:   40  train: 0.978  test: 0.953\n",
      "scale=    300.0  C=  10000.0  nSV:   33  train: 0.975  test: 0.935\n",
      "\n",
      "scale=   1000.0  C=     10.0  nSV:   67  train: 0.919  test: 0.922\n",
      "scale=   1000.0  C=    100.0  nSV:   61  train: 0.927  test: 0.937\n",
      "scale=   1000.0  C=   1000.0  nSV:   53  train: 0.873  test: 0.883\n",
      "scale=   1000.0  C=  10000.0  nSV:   40  train: 0.858  test: 0.880\n",
      "\n",
      "scale=   3000.0  C=     10.0  nSV:   83  train: 0.859  test: 0.869\n",
      "scale=   3000.0  C=    100.0  nSV:   70  train: 0.919  test: 0.925\n",
      "scale=   3000.0  C=   1000.0  nSV:   63  train: 0.910  test: 0.913\n",
      "scale=   3000.0  C=  10000.0  nSV:   50  train: 0.824  test: 0.847\n",
      "\n",
      "CPU times: user 5.73 s, sys: 94 ms, total: 5.83 s\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "D = sklearn.datasets.load_breast_cancer()\n",
    "X = D['data']\n",
    "T = (D['target']==1)*2.0-1.0\n",
    "\n",
    "for scale in [30,100,300,1000,3000]:\n",
    "    for C in [10,100,1000,10000]:\n",
    "        \n",
    "        acctrain,acctest,nbsvs = [],[],[]\n",
    "        \n",
    "        svm = GaussianSVM(C=C,scale=scale)\n",
    "        \n",
    "        for i in range(3):\n",
    "\n",
    "            # Split the data\n",
    "            R = numpy.random.mtrand.RandomState(i).permutation(len(X))\n",
    "            Xtrain,Xtest = X[R[:len(R)//2]]*1,X[R[len(R)//2:]]*1\n",
    "            Ttrain,Ttest = T[R[:len(R)//2]]*1,T[R[len(R)//2:]]*1\n",
    "\n",
    "            # Train and test the SVM\n",
    "            svm.fit(Xtrain,Ttrain)\n",
    "            acctrain += [(svm.predict(Xtrain)==Ttrain).mean()]\n",
    "            acctest  += [(svm.predict(Xtest)==Ttest).mean()]\n",
    "            nbsvs += [len(svm.X)*1.0]\n",
    "\n",
    "        print('scale=%9.1f  C=%9.1f  nSV: %4d  train: %.3f  test: %.3f'%(\n",
    "            scale,C,numpy.mean(nbsvs),numpy.mean(acctrain),numpy.mean(acctest)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
